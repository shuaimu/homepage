<HTML>
<HEAD>
<TITLE>./spring19/xigaoli/src/shardkv/server.go</TITLE>
</HEAD>
<BODY BGCOLOR=white>
<HR>
./spring19/xigaoli/src/shardkv/server.go<p><PRE>
package shardkv

// import "shardmaster"
import (
	"bytes"
	"encoding/gob"
	"labgob"
	"labrpc"
	"log"
	"raft"
	"shardmaster"
	"sync"
	"time"
)

//Debug .
const Debug = 0

// DPrintf .debug
func DPrintf(format string, a ...interface{}) (n int, err error) {
	if Debug &gt; 0 {
		log.Printf(format, a...)
	}
	return
}

type Op struct {
	// Your definitions here.
	// Field names must start with capital letters,
	// otherwise RPC will break.
	OPType    string
	Key       string
	Value     string
	ID        int64
	RequestID int32
}

type ShardKV struct {
	mu           sync.Mutex
	me           int
	rf           *raft.Raft
	applyCh      chan raft.ApplyMsg
	make_end     func(string) *labrpc.ClientEnd
	gid          int
	masters      []*labrpc.ClientEnd
	maxraftstate int // snapshot if log grows this big

	uid int64
	cfg shardmaster.Config
	mck *shardmaster.Clerk

	shouldStop bool

	// Your definitions here.
	db  [shardmaster.NShards]map[string]string
	ack map[int64]int32

	rslt map[int]chan Op
}

// AppendEntryToRaft .
<A NAME="2"></A><FONT color = #0000FF><A HREF="match211-1.html#2" TARGET="1"><IMG SRC="../../bitmaps/tm_2_2.gif" ALT="other" BORDER="0" ALIGN=left></A>

func (kv *ShardKV) AppendEntryToRaft(entry Op) bool {
	//append to raft here

	index, _, isLeader := kv.rf.Start(entry)
	if !isLeader {
		return false
	}

	kv.mu.Lock()

	ch, ok := kv.rslt[index]
	if !ok {
</FONT>		ch = make(chan Op, 10)
		kv.rslt[index] = ch
	}
	kv.mu.Unlock()
	// if entry.OPType == "Put" && entry.Key == "x" {
	// 	kv.db[entry.Key] = entry.Value
	// 	return true
	// }
	//apply locally immediately
	// if !kv.isAlreadyApplied(entry.ID, entry.RequestID) {

	// 	kv.startApplytoDB(entry)
	// 	return true
	// }
	select {
	case op := &lt;-ch:
		if op == entry {
			//DPrintf("#op=%v, entry=%v\n", op, entry)
			if op.OPType == "Put" {
				//kv.db[op.Key] = op.Value
				//bug fix, kludge
			}
			return true
		}
		return false
	case &lt;-time.After(500 * time.Millisecond):
		DPrintf("appendentry to raft Timeout\n")
		return false
	}

}

// Get
func (kv *ShardKV) Get(args *GetArgs, reply *GetReply) {
	// Your code here.
	entry := Op{OPType: "Get", Key: args.Key, ID: args.ID, RequestID: int32(args.RequestID)}
	//DPrintf("Get: kv-DB=%v\n\n", kv.db)
	DPrintf("Get entry:%v\n", entry)
	ok := kv.AppendEntryToRaft(entry)
	if !ok {
		reply.WrongLeader = true
	} else {
		reply.WrongLeader = false

		if !kv.CheckValidKey(args.Key) {
			reply.Err = ErrWrongGroup
			DPrintf("ERR:Wrong Group\n")
			return
		}

		reply.Err = OK
		kv.mu.Lock()
		reply.Value = kv.db[key2shard(args.Key)][args.Key]
		//reply.LeaderID = kv.me
		kv.ack[args.ID] = int32(args.RequestID)
		DPrintf("KV %d get:%v value:%v, db=%v\n", kv.me, args.Key, reply.Value, kv.db)
<A NAME="3"></A><FONT color = #00FFFF><A HREF="match211-1.html#3" TARGET="1"><IMG SRC="../../bitmaps/tm_3_1.gif" ALT="other" BORDER="0" ALIGN=left></A>

		kv.mu.Unlock()
	}
}

//PutAppend .
func (kv *ShardKV) PutAppend(args *PutAppendArgs, reply *PutAppendReply) {
	// Your code here.
	entry := Op{
		OPType:    args.Op,
</FONT>		Key:       args.Key,
		Value:     args.Value,
		ID:        args.ID,
		RequestID: int32(args.RequestID)}
	DPrintf("PutAppend entry:%v\n", entry)
	ok := kv.AppendEntryToRaft(entry)
	if ok {
		// find one available leader
		DPrintf("PutAppend found leader:%v\n", entry)

		reply.WrongLeader = false

		if !kv.CheckValidKey(args.Key) {
			reply.Err = ErrWrongGroup
			DPrintf("ERR:Wrong Group\n")
			return
		}

		reply.Err = OK
		kv.mu.Lock()
		reply.DBVal = kv.db[key2shard(args.Key)][args.Key]

		kv.mu.Unlock()
		//reply.LeaderID = kv.me
		//DPrintf("---kv.db=%v\n", kv.db)
	} else {
		// cannot find one leader
		reply.WrongLeader = true
	}
	return
}

//
// the tester calls Kill() when a ShardKV instance won't
// be needed again. you are not required to do anything
// in Kill(), but it might be convenient to (for example)
// turn off debug output from this instance.
//
func (kv *ShardKV) Kill() {
	kv.rf.Kill()
	// Your code here, if desired.
	kv.shouldStop = true
}

//
func (kv *ShardKV) isAlreadyApplied(id int64, reqid int32) bool {
	//kv.mu.Lock()
	//defer kv.mu.Unlock()

	v, ok := kv.ack[id]
	if ok {
		if v &gt;= reqid {

			//DPrintf("#OP already Processed- id=%v, reqid=%v, v=%v\n", id, reqid, v)
			return true
		}
	}
	return false
}

//CheckValidKey .
func (kv *ShardKV) CheckValidKey(key string) bool {
	kv.mu.Lock()
	defer kv.mu.Unlock()
	shardID := key2shard(key)
	if kv.gid != kv.cfg.Shards[shardID] {
		return false
	}
	return true
}
func (kv *ShardKV) startApplytoDB(args Op) {

	DPrintf("startApplytoDB:type=%v, key=%v, value=%v", args.OPType, args.Key, args.Value)
	switch args.OPType {
	case "Put":
		kv.db[key2shard(args.Key)][args.Key] = args.Value
		//DPrintf("PUT-%v=(%v)", args.Key, args.Value)
	case "Append":
		kv.db[key2shard(args.Key)][args.Key] += args.Value
		//DPrintf("APPEND-k=(%v),v+=(%v)=&gt;(%v)", args.Key, args.Value, kv.db[args.Key])
		//DPrintf("Append Success, kv.db=%v", kv.db)
	}

	kv.ack[args.ID] = args.RequestID
}

//
// servers[] contains the ports of the servers in this group.
//
// me is the index of the current server in servers[].
//
// the k/v server should store snapshots through the underlying Raft
// implementation, which should call persister.SaveStateAndSnapshot() to
// atomically save the Raft state along with the snapshot.
//
// the k/v server should snapshot when Raft's saved state exceeds
// maxraftstate bytes, in order to allow Raft to garbage-collect its
// log. if maxraftstate is -1, you don't need to snapshot.
//
// gid is this group's GID, for interacting with the shardmaster.
//
// pass masters[] to shardmaster.MakeClerk() so you can send
// RPCs to the shardmaster.
//
// make_end(servername) turns a server name from a
// Config.Groups[gid][i] into a labrpc.ClientEnd on which you can
// send RPCs. You'll need this to send RPCs to other groups.
//
// look at client.go for examples of how to use masters[]
// and make_end() to send RPCs to the group owning a specific shard.
//
// StartServer() must return quickly, so it should start goroutines
// for any long-running work.
//
func StartServer(servers []*labrpc.ClientEnd, me int, persister *raft.Persister, maxraftstate int, gid int, masters []*labrpc.ClientEnd, make_end func(string) *labrpc.ClientEnd) *ShardKV {
	// call labgob.Register on structures you want
	// Go's RPC library to marshall/unmarshall.
	labgob.Register(Op{})
	labgob.Register(PutAppendArgs{})
	labgob.Register(GetArgs{})
	labgob.Register(PutAppendReply{})
	labgob.Register(GetReply{})
	labgob.Register(shardmaster.Config{})

	kv := new(ShardKV)
	kv.me = me
	kv.maxraftstate = maxraftstate
	kv.make_end = make_end
	kv.gid = gid
	kv.masters = masters

	// Your initialization code here.

	kv.uid = nrand()
	//kv.db = make(map[string]string)
	kv.ack = make(map[int64]int32)
	kv.rslt = make(map[int]chan Op)
	kv.applyCh = make(chan raft.ApplyMsg, 1000)
	kv.rf = raft.Make(servers, me, persister, kv.applyCh)

	// Use something like this to talk to the shardmaster:
	// kv.mck = shardmaster.MakeClerk(kv.masters)
	kv.mck = shardmaster.MakeClerk(kv.masters)
	for i := 0; i &lt; shardmaster.NShards; i++ {
		kv.db[i] = make(map[string]string)
	}

	// kv.applyCh = make(chan raft.ApplyMsg)
	// kv.rf = raft.Make(servers, me, persister, kv.applyCh)
	go kv.recvMsgfromRaft()
	go kv.PollConfig()
	return kv
}

//PollConfig
func (kv *ShardKV) PollConfig() {
	for true {
		if _, isLeader := kv.rf.GetState(); isLeader {
			//DPrintln("server", kv.gid, kv.me, "is leader and run poll config")
			latestCfg := kv.mck.Query(-1)

			kv.mu.Lock()
			args := ReconfigureArgs{}
			args.Cfg = latestCfg
			for i := 0; i &lt; shardmaster.NShards; i++ {
				args.StoreShard[i] = make(map[string]string)
			}

			transShards := make(map[int][]int)
			//transshards[gid] means that originally [gid] is responsible for some shards,
			// but now it is my responsibility to handle those shards

			for i := 0; i &lt; shardmaster.NShards; i++ {
				if kv.cfg.Shards[i] != kv.gid && latestCfg.Shards[i] == kv.gid {
					//kv(gid) not responsible to some shard i in old config, but responsible for it now in new config
					gid := kv.cfg.Shards[i]
					//gid is old gid on old config
					if gid != 0 {
						if _, ok := transShards[gid]; !ok {
							//transShards[gid] does not have a value, then build an array with only 1 value
							transShards[gid] = []int{i}
						} else {
							//just append it.
							transShards[gid] = append(transShards[gid], i)
						}
					}
				}
			}
			//calculate the shards needs to be transferred

			kv.cfg = latestCfg
			kv.mu.Unlock()
			kv.ApplyReconfigure(args)
			/*
				for i := kv.cfg.Num + 1; i &lt;= latestCfg.Num; i++ {
					args, ok := kv.GetReconfigure(kv.mck.Query(i))
					if !ok {
						break
					}
					if !kv.SyncReconfigure(args) {
						break
					}
				}*/
		}
		time.Sleep(100 * time.Millisecond)
	}
}
func (kv *ShardKV) ApplyReconfigure(args ReconfigureArgs) {
	kv.mu.Lock()
	defer kv.mu.Unlock()

	if args.Cfg.Num &gt; kv.cfg.Num {
		// already reached consensus, merge db and ack
		for shardIndex, data := range args.StoreShard {
			for k, v := range data {
				kv.db[shardIndex][k] = v
			}
		}
		for clientId := range args.Ack {
			if _, exist := kv.ack[clientId]; !exist || kv.ack[clientId] &lt; int32(args.Ack[clientId]) {
				kv.ack[clientId] = int32(args.Ack[clientId])
			}
		}
		//??? copy of reference
		kv.cfg = args.Cfg
		DPrintf("Server %v, gid %v, applied reconfig %v\n", kv.gid, kv.me, args)

	}

	return
}

//recvMsgfromRaft .
func (kv *ShardKV) recvMsgfromRaft() {
	defer func() {
		// recover from panic if one occured. Set err to nil otherwise.
		if recover() != nil {
			DPrintf("catched error in recvMsgfromRaft\n")
			go kv.recvMsgfromRaft()
		}
	}()
	for {
		kv.mu.Lock()
		if kv.shouldStop == true {
			kv.mu.Unlock()
			return
		}
		kv.mu.Unlock()
<A NAME="1"></A><FONT color = #00FF00><A HREF="match211-1.html#1" TARGET="1"><IMG SRC="../../bitmaps/tm_1_3.gif" ALT="other" BORDER="0" ALIGN=left></A>

		select {
		case msg := &lt;-kv.applyCh:
			//DPrintf("get new applied msg (%v)", msg)
			if msg.HaveSnapshot {
				var LastIncludedIndex int
				var LastIncludedTerm int

				r := bytes.NewBuffer(msg.Snapshot)
				d := gob.NewDecoder(r)

				kv.mu.Lock()
				d.Decode(&LastIncludedIndex)
				d.Decode(&LastIncludedTerm)
</FONT>				//kv.db = make([shardmaster.NShards]map[string]string)
				for i := 0; i &lt; shardmaster.NShards; i++ {
					kv.db[i] = make(map[string]string)
				}
				kv.ack = make(map[int64]int32)

<A NAME="4"></A><FONT color = #FF00FF><A HREF="match211-1.html#4" TARGET="1"><IMG SRC="../../bitmaps/tm_4_1.gif" ALT="other" BORDER="0" ALIGN=left></A>

				d.Decode(&kv.db)
				d.Decode(&kv.ack)
				//DPrintf("SNAPSHOT: get snap: kv.db=%v\n", kv.db)
				kv.mu.Unlock()
			} else {
				op := msg.Command.(Op)
</FONT>				kv.mu.Lock()
				if !kv.isAlreadyApplied(op.ID, op.RequestID) {

					kv.startApplytoDB(op)
				} else {
					DPrintf("OP already Processed- op=%v , key=%v, DBVal=%v\n", op, op.Key, kv.db[key2shard(op.Key)][op.Key])
				}

				ch, ok := kv.rslt[msg.CommandIndex]
				if ok {
					// select {
					// case &lt;-kv.rslt[msg.CommandIndex]:
					// default:
					// }
					//DPrintf("Insert %v into ch, key=%v, DBVal=%v\n", op, op.Key, kv.db[op.Key])
					//time.Sleep(20 * time.Millisecond)
					//do not sleep here
					ch &lt;- op
				} else {
<A NAME="0"></A><FONT color = #FF0000><A HREF="match211-1.html#0" TARGET="1"><IMG SRC="../../bitmaps/tm_0_4.gif" ALT="other" BORDER="0" ALIGN=left></A>

					kv.rslt[msg.CommandIndex] = make(chan Op, 10)
					//new one
				}

				//need snapshot
				if kv.maxraftstate != -1 && kv.rf.GetPerisistSize() &gt; kv.maxraftstate {
					w := new(bytes.Buffer)
					e := gob.NewEncoder(w)
					e.Encode(kv.db)
					e.Encode(kv.ack)
					data := w.Bytes()
					//DPrintf("start one snapshot, kv.db=%v\n", kv.db)
					go kv.rf.StartSnapshot(data, msg.CommandIndex)
				}

				kv.mu.Unlock()
			}
		case &lt;-time.After(1000 * time.Millisecond):
</FONT>			//prevent dead here
			if kv.shouldStop == true {

				return
			}
			continue
		}
	}
}
</PRE>
</PRE>
</BODY>
</HTML>
